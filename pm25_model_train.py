import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns 
import joblib
import shap # ğŸš€ æ–°å¢ SHAP åº«å°å…¥


# --- è¨­å®šå„ªåŒ–éšæ®µåƒæ•¸ ---
N_HOURS_AHEAD = 24 


# --- 1. æ•¸æ“šè¼‰å…¥èˆ‡ç‰¹å¾µå®šç¾© ---
file_path = "la_pm25_combined_clean_v13.csv"
try:
    df = pd.read_csv(file_path, index_col='DateTime', parse_dates=True)
except FileNotFoundError:
    print(f"ğŸš¨ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ã€‚è«‹ç¢ºä¿å®ƒèˆ‡è…³æœ¬åœ¨åŒä¸€ç›®éŒ„ä¸‹ã€‚")
    exit()

print("--- æ¨¡å‹è¨“ç·´æº–å‚™éšæ®µ ---")
print(f"è¼‰å…¥æ•¸æ“šé›†ç¸½è¨˜éŒ„æ•¸: {len(df)}")

# å®šç¾©ç›®æ¨™è®Šé‡ (y) - ä½¿ç”¨ t+N çš„æ•¸å€¼
target_variable = 'PM25'
y = df[target_variable].shift(-N_HOURS_AHEAD)


# å®šç¾©æ°£è±¡ç‰¹å¾µ (X)
feature_columns = [
    'HourlyDryBulbTemperature', 
    'HourlyRelativeHumidity', 
    'HourlyWindSpeed', 
    'HourlyDewPointTemperature', 
    'HourlyStationPressure', 
    'HourlySeaLevelPressure', 
    'HourlyVisibility'
]
X = df[feature_columns].copy()


# --- 1.5. æ–°å¢ï¼šç›®æ¨™è®Šé‡çš„æ»¯å¾Œç‰¹å¾µ (Lagged Feature) ---
# ğŸš€ é—œéµå„ªåŒ– 1: åŠ å…¥ N å°æ™‚å‰çš„ PM2.5 æ•¸å€¼
X[f'PM25_Lag_{N_HOURS_AHEAD}'] = df[target_variable].shift(N_HOURS_AHEAD)

# ğŸŒŸ é—œéµå„ªåŒ– 2: åŠ å…¥ N å°æ™‚å‰çš„ 24 å°æ™‚æ»¾å‹•å¹³å‡ (Rolling Mean)
rolling_mean = df[target_variable].rolling(window=24).mean()
X[f'PM25_RollingMean_24hr_Lag_{N_HOURS_AHEAD}'] = rolling_mean.shift(N_HOURS_AHEAD)
print("âœ… æ–°å¢ PM2.5 éå» 24 å°æ™‚å¹³å‡å€¼ç‰¹å¾µï¼")


# --- 2. å‰µå»ºæ™‚é–“ç›¸é—œç‰¹å¾µ (ç‰¹å¾µå·¥ç¨‹) ---
print("âš™ï¸ é€²è¡Œæ™‚é–“ç‰¹å¾µå·¥ç¨‹...")
X['DayOfWeek'] = X.index.dayofweek
X['Month'] = X.index.month

# ğŸ’¡ å¢åŠ æ™‚é–“çš„å¾ªç’°ç‰¹å¾µ (ä¸è®Š)
X['Hour'] = X.index.hour
X['Hour_sin'] = np.sin(2 * np.pi * X['Hour'] / 24)
X['Hour_cos'] = np.cos(2 * np.pi * X['Hour'] / 24)
X = X.drop('Hour', axis=1) # ç§»é™¤åŸå§‹çš„ Hour æ¬„ä½


# --- 2.5. æ¸…ç† NaN å€¼å’Œå°é½Š X èˆ‡ y (æ•¸æ“šå°é½Šæ˜¯æˆåŠŸçš„é—œéµ) ---
combined_df = pd.concat([X, y.rename('Target_PM25')], axis=1).dropna()

# é‡æ–°å®šç¾© X å’Œ y
X = combined_df.drop('Target_PM25', axis=1)
y = combined_df['Target_PM25']

print(f"å®šç¾©æ»¯å¾Œç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸å¾Œï¼Œæœ€çµ‚æœ‰æ•ˆè¨˜éŒ„æ•¸: {len(X)}")
print(f"æœ€çµ‚ç‰¹å¾µ (X) æ•¸é‡: {X.shape[1]}")


# --- 3. æ•¸æ“šé›†åŠƒåˆ† (éš¨æ©ŸåŠƒåˆ†ï¼š80% è¨“ç·´ / 20% æ¸¬è©¦) ---
print("\nâš™ï¸ é€²è¡Œéš¨æ©ŸåŠƒåˆ†ï¼š80% è¨“ç·´ / 20% æ¸¬è©¦...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"è¨“ç·´é›† (80%) è¨˜éŒ„æ•¸: {len(X_train)}")
print(f"æ¸¬è©¦é›† (20%) è¨˜éŒ„æ•¸: {len(X_test)}")


# --- 4. æ¨¡å‹è¨“ç·´ (éš¨æ©Ÿæ£®æ—å›æ­¸) ---
print(f"\nâš™ï¸ é–‹å§‹è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹ (é æ¸¬ t+{N_HOURS_AHEAD} å°æ™‚)...")
model = RandomForestRegressor(n_estimators=100, 
                              max_depth=10, 
                              random_state=42, 
                              n_jobs=-1)
model.fit(X_train, y_train)
print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼")


# --- 5. æ¨¡å‹è©•ä¼° ---
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n--- æ¨¡å‹æ€§èƒ½è©•ä¼° (æ–°æŒ‘æˆ°æ¸¬è©¦é›†) ---")
print(f"é æ¸¬æ™‚é–“ï¼š{N_HOURS_AHEAD} å°æ™‚å¾Œ")
print(f"å¹³å‡çµ•å°èª¤å·® (RMSE): {rmse:.2f}")
print(f"æ±ºå®šä¿‚æ•¸ (RÂ²): {r2:.4f}")


# --- 6. ç‰¹å¾µé‡è¦æ€§åˆ†æ ---
feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)
print("\n--- é ‚éƒ¨ 5 å€‹é‡è¦ç‰¹å¾µ (æ»¯å¾Œç‰¹å¾µå½±éŸ¿åˆ†æ) ---")
print(feature_importances.nlargest(5))


# --- 7. æ¨¡å‹å„²å­˜ (Save Model) ---
model_filename = f'pm25_rf_predict_{N_HOURS_AHEAD}hr_v2.joblib' 
try:
    joblib.dump(model, model_filename)
    # ç”±æ–¼æ¨¡å‹æª”æ¡ˆé€šå¸¸å¾ˆå¤§ï¼Œæˆ‘å€‘ä¸æ‡‰è©²å°‡å…¶æ¨é€åˆ° Gitï¼Œå› æ­¤é€™è£¡è¨»é‡‹æ‰äº†é—œæ–¼ Git çš„èªªæ˜
    print(f"\nâœ… æ¨¡å‹å·²æˆåŠŸå„²å­˜è‡³ {model_filename}ï¼")
except Exception as e:
    print(f"\nğŸš¨ æ¨¡å‹å„²å­˜å¤±æ•—: {e}")


# --- 8. è¦–è¦ºåŒ–è¨­ç½® ---
print("\n--- ç¹ªè£½è¦–è¦ºåŒ–åœ–è¡¨ ---")
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("colorblind") 


# --- åœ–è¡¨ 1 & 2: é æ¸¬å°æ¯”èˆ‡å‚³çµ±ç‰¹å¾µé‡è¦æ€§ (èˆ‡ä¹‹å‰ç›¸åŒï¼Œç•¥) ---
# ... [é€™éƒ¨åˆ†ä»£ç¢¼èˆ‡æ‚¨æä¾›çš„ V2 ç‰ˆæœ¬å®Œå…¨ç›¸åŒï¼Œå› æ­¤ç‚ºäº†ç°¡æ½”é€™è£¡çœç•¥]
# ... [ç¢ºä¿æ‚¨æœ¬åœ°è…³æœ¬ä¸­é€™éƒ¨åˆ†ä»ç„¶å­˜åœ¨]


# -----------------------------------------------------------
# ğŸŒŸ é—œéµå„ªåŒ– 3: SHAP å¯è§£é‡‹æ€§åˆ†æ (Explaining the Model)
# -----------------------------------------------------------
print("\nâš™ï¸ åŸ·è¡Œ SHAP åˆ†æï¼Œè§£é‡‹æ¨¡å‹æ±ºç­–...")

# 1. å‰µå»º Explainer
# ç”±æ–¼ Random Forest æ˜¯æ¨¹æ¨¡å‹ï¼Œæˆ‘å€‘ä½¿ç”¨ TreeExplainerï¼Œé€Ÿåº¦æœ€å¿«ã€ç²¾åº¦æœ€é«˜
explainer = shap.TreeExplainer(model)

# 2. è¨ˆç®— SHAP å€¼
# ç‚ºäº†é€Ÿåº¦å’Œæº–ç¢ºæ€§ï¼Œæˆ‘å€‘åªåœ¨æ¸¬è©¦é›†çš„ä¸€å€‹å­æ¨£æœ¬ä¸Šé‹è¡Œ SHAP (ä¾‹å¦‚ 500 å€‹æ¨£æœ¬)
X_sample = X_test.sample(n=500, random_state=42) 
shap_values = explainer.shap_values(X_sample)

# 3. ç¹ªè£½ SHAP æ‘˜è¦åœ–
# é€™å¼µåœ–æ˜¯ SHAP å ±å‘Šçš„æ ¸å¿ƒï¼Œå±•ç¤ºäº†æ¯å€‹ç‰¹å¾µçš„å½±éŸ¿æ–¹å‘å’Œåˆ†ä½ˆ
plt.figure(figsize=(10, 7))
shap.summary_plot(shap_values, X_sample, 
                  plot_type='dot', 
                  show=False, 
                  title=f'SHAP Feature Impact (Predicting T+{N_HOURS_AHEAD}hr PM2.5)')

# èª¿æ•´ä½ˆå±€ä¸¦ä¿å­˜
plt.tight_layout()
shap_filename = f'shap_summary_plot_{N_HOURS_AHEAD}hr_v2.png'
plt.savefig(shap_filename, bbox_inches='tight')
plt.close() # é—œé–‰åœ–è¡¨ï¼Œé¿å…å…§å­˜æ´©æ¼

print(f"âœ… åœ–è¡¨ 3: SHAP æ‘˜è¦åœ– ({shap_filename}) å·²ä¿å­˜")

print("\nğŸ‰ æˆæœè¦–è¦ºåŒ–å’Œ SHAP åˆ†æå®Œæˆï¼è«‹æª¢æŸ¥åŒç›®éŒ„ä¸‹çš„åœ–ç‰‡æª”æ¡ˆã€‚")
# --- ç¨‹å¼ç¢¼çµæŸ ---