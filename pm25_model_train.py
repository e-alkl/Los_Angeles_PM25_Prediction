import pandas as pd
from xgboost import XGBRegressor 
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import joblib

# --- è¨­å®šåƒæ•¸ ---
N_HOURS_AHEAD = 24  # é æ¸¬ 24 å°æ™‚å¾Œçš„ PM2.5

# å®šç¾©æ½›åœ¨çš„ç‰¹å¾µæ¬„ä½ (èˆ‡ä¹‹å‰ä¿æŒä¸€è‡´)
FEATURE_AND_TARGET_COLUMNS = [
    'PM25', 
    'HourlyDryBulbTemperature', 'HourlyRelativeHumidity', 
    'HourlyWindSpeed', 'HourlyDewPointTemperature', 
    'HourlyStationPressure', 
    'HourlyVisibility' 
]

# --- 1. æ•¸æ“šè¼‰å…¥èˆ‡é è™•ç† (ä¿æŒèˆ‡æœ€çµ‚ç‰ˆæœ¬ä¸€è‡´) ---
file_path = "la_pm25_combined_clean_v15_2019_2024.csv" 
try:
    df = pd.read_csv(file_path, index_col='DateTime', parse_dates=True)
except FileNotFoundError:
    print(f"ğŸš¨ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ã€‚")
    exit()

print("--- æ¨¡å‹è¨“ç·´æº–å‚™éšæ®µ ---")
original_len = len(df)

if df.index.tz is not None:
    df.index = df.index.tz_localize(None)

for col in FEATURE_AND_TARGET_COLUMNS:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').astype('float64')

cols_to_drop = []
for col in FEATURE_AND_TARGET_COLUMNS:
    if col in df.columns and df[col].isnull().sum() == original_len:
        cols_to_drop.append(col)

FEATURE_AND_TARGET_COLUMNS = [c for c in FEATURE_AND_TARGET_COLUMNS if c not in cols_to_drop]
df = df[FEATURE_AND_TARGET_COLUMNS].copy()

df = df.fillna(method='ffill').fillna(method='bfill')
df.dropna(inplace=True) 

print(f"åŸå§‹æ•¸æ“šæ¡†ç¶“éåš´æ ¼æ¸…æ´—å¾Œçš„è¨˜éŒ„æ•¸: {len(df)}")


# --- 2. ç‰¹å¾µå·¥ç¨‹ (ä¿æŒä¸€è‡´) ---
target_variable = 'PM25'
y = df[target_variable].shift(-N_HOURS_AHEAD)
feature_columns = [c for c in FEATURE_AND_TARGET_COLUMNS if c != 'PM25']
X = df[feature_columns].copy()

X[f'PM25_Lag_{N_HOURS_AHEAD}'] = df[target_variable].shift(N_HOURS_AHEAD)
rolling_mean = df[target_variable].rolling(window=24).mean()
X[f'PM25_RollingMean_24hr_Lag_{N_HOURS_AHEAD}'] = rolling_mean.shift(N_HOURS_AHEAD)

X['DayOfWeek'] = X.index.dayofweek
X['Month'] = X.index.month
X['Hour'] = X.index.hour
X['Hour_sin'] = np.sin(2 * np.pi * X['Hour'] / 24)
X['Hour_cos'] = np.cos(2 * np.pi * X['Hour'] / 24)
X = X.drop('Hour', axis=1) 

combined_df = pd.concat([X, y.rename('Target_PM25')], axis=1).dropna() 

X = combined_df.drop('Target_PM25', axis=1)
y = combined_df['Target_PM25']
print(f"æœ€çµ‚æœ‰æ•ˆè¨˜éŒ„æ•¸ (ç¶“é 2019-2024 å¹´æ¸…æ´—å’Œå°é½Š): {len(X)}")
print(f"æœ€çµ‚ç‰¹å¾µ (X) æ•¸é‡: {X.shape[1]}")


# -----------------------------------------------------------------
# ğŸš€ æ™‚é–“é †åºåŠƒåˆ† (Time Series Split)
# -----------------------------------------------------------------
split_date = pd.to_datetime('2024-01-01')

X_train = X[X.index < split_date]
y_train = y[y.index < split_date]

X_test = X[X.index >= split_date]
y_test = y[y.index >= split_date]

print(f"\nâš™ï¸ é€²è¡Œæ™‚é–“é †åºåŠƒåˆ†ï¼š2019-2023 å¹´è¨“ç·´ / 2024 å¹´æ¸¬è©¦...Â Â ")
print(f"è¨“ç·´é›† (2019-2023 å¹´) è¨˜éŒ„æ•¸: {len(X_train)}")
print(f"æ¸¬è©¦é›† (2024 å¹´) è¨˜éŒ„æ•¸: {len(X_test)}")


# --- 4. æ¨¡å‹è¨“ç·´ (XGBoost å›æ­¸ - å„ªåŒ–ç‰ˆæœ¬) ---
print(f"\nâš™ï¸ é–‹å§‹è¨“ç·´ XGBoost å„ªåŒ–æ¨¡å‹ (é æ¸¬ t+{N_HOURS_AHEAD} å°æ™‚)...")

# ğŸŒŸ å„ªåŒ–èª¿æ•´ ğŸŒŸ
model_optimized = XGBRegressor(
    n_estimators=200,                # å¢åŠ ä¼°è¨ˆå™¨æ•¸é‡
    max_depth=7,                     # å¢åŠ æ¨¹çš„æ·±åº¦
    learning_rate=0.1, 
    random_state=42, 
    n_jobs=-1,
    objective='reg:absoluteerror'    # åˆ‡æ›åˆ° MAE æå¤±å‡½æ•¸ï¼Œæ—¨åœ¨ä¿®æ­£ä½æ¿ƒåº¦åå·®
)

# è™•ç† XGBoost ç‰¹å¾µå‘½åé™åˆ¶
X_train.columns = [c.replace(':', '_').replace('<', '_') for c in X_train.columns]
X_test.columns = [c.replace(':', '_').replace('<', '_') for c in X_test.columns]

model_optimized.fit(X_train, y_train)
print("âœ… XGBoost å„ªåŒ–æ¨¡å‹è¨“ç·´å®Œæˆï¼")


# --- 5. æ¨¡å‹è©•ä¼° (æ¸¬è©¦é›†ç‚º 2024 å¹´æ•¸æ“š) ---
if len(y_test) > 0:
    y_pred_optimized = model_optimized.predict(X_test)
    
    # çµ‚æ¥µä¿®æ­£ï¼šæ‰‹å‹•ä¿®æ­£ 1 å°æ™‚éŒ¯ä½ï¼ˆç¢ºä¿æ€§èƒ½è¨ˆç®—æ­£ç¢ºï¼‰
    y_test_aligned = y_test.values[1:] 
    y_pred_aligned = y_pred_optimized[:-1]
    
    # ç¢ºä¿é•·åº¦ä¸€è‡´
    if len(y_test_aligned) != len(y_pred_aligned):
        y_test_aligned = y_test.values
        y_pred_aligned = y_pred_optimized
    
    mse = mean_squared_error(y_test_aligned, y_pred_aligned)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test_aligned, y_pred_aligned)

    print("\n--- æ¨¡å‹æ€§èƒ½è©•ä¼° (XGBoost å„ªåŒ–ç‰ˆ + 2024 æ¸¬è©¦) ---")
    print(f"é æ¸¬æ™‚é–“ï¼š{N_HOURS_AHEAD} å°æ™‚å¾Œ")
    print(f"å¹³å‡çµ•å°èª¤å·® (RMSE): {rmse:.4f} (ç›®æ¨™æ˜¯ä½æ–¼ 5.69)")
    print(f"æ±ºå®šä¿‚æ•¸ (RÂ²): {r2:.4f} (ç›®æ¨™æ˜¯æ­£å€¼ï¼Œç´„ 0.70-0.75)")

    # --- 6. ç‰¹å¾µé‡è¦æ€§åˆ†æ ---
    feature_importances = pd.Series(model_optimized.feature_importances_, index=X_train.columns)
    print("\n--- é ‚éƒ¨ 5 å€‹é‡è¦ç‰¹å¾µ (å„ªåŒ–æ¨¡å‹) ---")
    print(feature_importances.nlargest(5))

    # --- 7. æ¨¡å‹å„²å­˜ ---
    model_filename = f'pm25_xgb_optimized_predict_{N_HOURS_AHEAD}hr_2019_2023_train.joblib' 
    try:
        joblib.dump(model_optimized, model_filename)
        print(f"\nâœ… å„ªåŒ–æ¨¡å‹å·²æˆåŠŸå„²å­˜è‡³ {model_filename}ï¼")
    except Exception as e:
        print(f"\nğŸš¨ æ¨¡å‹å„²å­˜å¤±æ•—: {e}")
else:
    print("\nğŸš¨ è­¦å‘Šï¼šæ¸¬è©¦é›†ç‚ºç©ºï¼ç„¡æ³•é€²è¡Œæ€§èƒ½è©•ä¼°ã€‚")