import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns 
import joblib

# --- 1. æ•¸æ“šè¼‰å…¥èˆ‡ç‰¹å¾µå®šç¾© ---
# è¼‰å…¥ V13 æ¸…æ´—å®Œæˆçš„æ•¸æ“šé›†
file_path = "la_pm25_combined_clean_v13.csv"
try:
    # ğŸš¨ ç¢ºä¿é€™è£¡æœ‰ df è®Šæ•¸çš„å®šç¾©
    df = pd.read_csv(file_path, index_col='DateTime', parse_dates=True)
except FileNotFoundError:
    print(f"ğŸš¨ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}ã€‚è«‹ç¢ºä¿å®ƒèˆ‡è…³æœ¬åœ¨åŒä¸€ç›®éŒ„ä¸‹ã€‚")
    exit()

print("--- æ¨¡å‹è¨“ç·´æº–å‚™éšæ®µ ---")
print(f"è¼‰å…¥æ•¸æ“šé›†ç¸½è¨˜éŒ„æ•¸: {len(df)}")

# å®šç¾©ç›®æ¨™è®Šé‡ (y)
target_variable = 'PM25'
y = df[target_variable]

# å®šç¾©æ°£è±¡ç‰¹å¾µ (X)
feature_columns = [
    'HourlyDryBulbTemperature', 
    'HourlyRelativeHumidity', 
    'HourlyWindSpeed', 
    'HourlyDewPointTemperature', 
    'HourlyStationPressure', 
    'HourlySeaLevelPressure', 
    'HourlyVisibility'
]
X = df[feature_columns].copy()

# --- 1.5. æ–°å¢ï¼šç›®æ¨™è®Šé‡çš„æ»¯å¾Œç‰¹å¾µ (Lagged Feature) ---
# é€™æ˜¯æå‡ R^2 çš„é—œéµã€‚
X['PM25_Lag_1'] = y.shift(1)

# ç”±æ–¼ç¬¬ä¸€å€‹å°æ™‚ (t=0) æ²’æœ‰ t-1 çš„å€¼ï¼Œæœƒç”¢ç”Ÿ NaNã€‚
# æˆ‘å€‘éœ€è¦åˆªé™¤ç¬¬ä¸€å€‹å°æ™‚çš„è¨˜éŒ„ï¼Œä»¥ç¢ºä¿æ•¸æ“šå®Œæ•´æ€§ã€‚
X.dropna(inplace=True) 
y = y[X.index] # ç¢ºä¿ y ä¹Ÿè¢«åŒæ­¥æˆªæ–·ï¼Œä¿æŒåš´æ ¼å°é½Š

print(f"æ–°å¢ PM2.5 æ»¯å¾Œç‰¹å¾µå¾Œï¼Œç¸½è¨˜éŒ„æ•¸è®Šç‚º: {len(X)}")

# --- 2. å‰µå»ºæ™‚é–“ç›¸é—œç‰¹å¾µ (ç‰¹å¾µå·¥ç¨‹) ---
print("âš™ï¸ é€²è¡Œæ™‚é–“ç‰¹å¾µå·¥ç¨‹...")

# å¾ç´¢å¼•æå–æ™‚é–“ç‰¹å¾µ
X['DayOfWeek'] = X.index.dayofweek
X['Month'] = X.index.month

# ğŸ’¡ å¢åŠ æ™‚é–“çš„å¾ªç’°ç‰¹å¾µ
X['Hour'] = X.index.hour
X['Hour_sin'] = np.sin(2 * np.pi * X['Hour'] / 24)
X['Hour_cos'] = np.cos(2 * np.pi * X['Hour'] / 24)
X = X.drop('Hour', axis=1) # ç§»é™¤åŸå§‹çš„ Hour æ¬„ä½

print(f"æœ€çµ‚ç‰¹å¾µ (X) æ•¸é‡: {X.shape[1]}")


# --- 3. æ•¸æ“šé›†åŠƒåˆ† (éš¨æ©ŸåŠƒåˆ†ï¼š80% è¨“ç·´ / 20% æ¸¬è©¦) ---
print("\nâš™ï¸ é€²è¡Œéš¨æ©ŸåŠƒåˆ†ï¼š80% è¨“ç·´ / 20% æ¸¬è©¦...")

# ä½¿ç”¨ train_test_split ç¢ºä¿ X å’Œ y å®Œç¾å°é½Š
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"è¨“ç·´é›† (80%) è¨˜éŒ„æ•¸: {len(X_train)}")
print(f"æ¸¬è©¦é›† (20%) è¨˜éŒ„æ•¸: {len(X_test)}")


# --- 4. æ¨¡å‹è¨“ç·´ (éš¨æ©Ÿæ£®æ—å›æ­¸) ---
print("\nâš™ï¸ é–‹å§‹è¨“ç·´éš¨æ©Ÿæ£®æ—å›æ­¸æ¨¡å‹ (V2.0)...")
# ä¿æŒ max_depth=10 ä»¥æ§åˆ¶æ¨¡å‹è¤‡é›œåº¦
model = RandomForestRegressor(n_estimators=100, 
                              max_depth=10, 
                              random_state=42, 
                              n_jobs=-1)
model.fit(X_train, y_train)
print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼")


# --- 5. æ¨¡å‹è©•ä¼° ---
y_pred = model.predict(X_test)

# è¨ˆç®—è©•ä¼°æŒ‡æ¨™
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n--- æ¨¡å‹æ€§èƒ½è©•ä¼° (V2.0 æ¸¬è©¦é›†) ---")
print(f"å¹³å‡çµ•å°èª¤å·® (RMSE): {rmse:.2f}")
print(f"æ±ºå®šä¿‚æ•¸ (RÂ²): {r2:.4f}")


# --- 6. ç‰¹å¾µé‡è¦æ€§åˆ†æ ---
feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)
print("\n--- é ‚éƒ¨ 5 å€‹é‡è¦ç‰¹å¾µ (æ»¯å¾Œç‰¹å¾µå½±éŸ¿åˆ†æ) ---")
print(feature_importances.nlargest(5))

# --- 7. æ¨¡å‹å„²å­˜ (Save Model) ---
model_filename = 'pm25_random_forest_v2.0.joblib'

try:
    # ä½¿ç”¨ joblib å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹ (model è®Šæ•¸)
    joblib.dump(model, model_filename)
    print(f"\nâœ… æ¨¡å‹å·²æˆåŠŸå„²å­˜è‡³ {model_filename}ï¼")
except Exception as e:
    print(f"\nğŸš¨ æ¨¡å‹å„²å­˜å¤±æ•—: {e}")

# --- 8. è¦–è¦ºåŒ–è¨­ç½® ---
print("\n--- 7. ç¹ªè£½è¦–è¦ºåŒ–åœ–è¡¨ ---")
plt.style.use('seaborn-v0_8-whitegrid') # è¨­ç½®åœ–è¡¨é¢¨æ ¼
sns.set_palette("colorblind") # è¨­ç½®é¡è‰²ä¸»é¡Œ


# --- åœ–è¡¨ 1: é æ¸¬èˆ‡å¯¦éš›å€¼å°æ¯” (æ™‚é–“åºåˆ—) ---
# é¸æ“‡æ¸¬è©¦é›† (20% æ•¸æ“š) ä¸­ä¸€æ®µä»£è¡¨æ€§çš„æ™‚é–“ç¯„åœä¾†å±•ç¤ºé«˜æº–ç¢ºåº¦
# é€™è£¡æˆ‘å€‘éš¨æ©Ÿé¸æ“‡æ¸¬è©¦é›†ä¸­çš„ 24*7 = 168 å€‹é€£çºŒå°æ™‚ (ä¸€å‘¨)
n_hours = 168
start_index = np.random.randint(0, len(y_test) - n_hours)

# å‰µå»ºä¸€å€‹ DataFrame åŒ…å«å¯¦éš›å€¼å’Œé æ¸¬å€¼
plot_df = pd.DataFrame({
    'Actual PM2.5': y_test.iloc[start_index : start_index + n_hours],
    'Predicted PM2.5': y_pred[start_index : start_index + n_hours]
})

plt.figure(figsize=(15, 6))
plt.plot(plot_df.index, plot_df['Actual PM2.5'], label='Actual PM2.5', color='blue', linewidth=2)
plt.plot(plot_df.index, plot_df['Predicted PM2.5'], label='Predicted PM2.5', color='red', linestyle='--', linewidth=1.5)

plt.title(f'PM2.5 é æ¸¬èˆ‡å¯¦éš›å€¼å°æ¯” (ä¸€é€±æ¨£æœ¬)\n (RMSE: {rmse:.2f} | RÂ²: {r2:.4f})', fontsize=16)
plt.xlabel('æ™‚é–“ (DateTime)', fontsize=12)
plt.ylabel(r'PM$_{2.5}$ $(\mu g/m^3)$', fontsize=12)
plt.legend(fontsize=10)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('pm25_prediction_vs_actual.png')
print("âœ… åœ–è¡¨ 1: é æ¸¬èˆ‡å¯¦éš›å€¼å°æ¯” (pm25_prediction_vs_actual.png) å·²ä¿å­˜")
# plt.show() # å¦‚æœåœ¨ Jupyter/Colab ä¸­é‹è¡Œï¼Œå–æ¶ˆè¨»é‡‹æ­¤è¡Œ


# --- åœ–è¡¨ 2: ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Importance) ---
# ä½¿ç”¨ä½ åœ¨ Section 6 è¨ˆç®—çš„ feature_importances
# é¸æ“‡å‰ 10 å€‹æœ€é‡è¦çš„ç‰¹å¾µä¾†å±•ç¤º (PM25_Lag_1 æœƒä½”æ“šçµ•å°å„ªå‹¢)
top_n = feature_importances.nlargest(10).sort_values(ascending=True)

plt.figure(figsize=(10, 7))
top_n.plot(kind='barh', color='darkgreen')

plt.title('ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Importance)', fontsize=16)
plt.xlabel('é‡è¦æ€§åˆ†æ•¸ (Normalized Score)', fontsize=12)
plt.ylabel('ç‰¹å¾µåç¨±', fontsize=12)
plt.tight_layout()
plt.savefig('feature_importance.png')
print("âœ… åœ–è¡¨ 2: ç‰¹å¾µé‡è¦æ€§åˆ†æ (feature_importance.png) å·²ä¿å­˜")
# plt.show() # å¦‚æœåœ¨ Jupyter/Colab ä¸­é‹è¡Œï¼Œå–æ¶ˆè¨»é‡‹æ­¤è¡Œ

print("\nğŸ‰ æˆæœè¦–è¦ºåŒ–å®Œæˆï¼è«‹æª¢æŸ¥åŒç›®éŒ„ä¸‹çš„åœ–ç‰‡æª”æ¡ˆã€‚")